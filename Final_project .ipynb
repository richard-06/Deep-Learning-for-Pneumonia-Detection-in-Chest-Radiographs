{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Imports and path to Dataset"
      ],
      "metadata": {
        "id": "oU4KFlDZ9fqI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-ATgI-Uphxpd"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# my Imports\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, Model, preprocessing, backend\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "\n",
        "from keras.layers import Input, BatchNormalization, Activation, Concatenate, AveragePooling2D\n",
        "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jylu3e-6hwaj"
      },
      "outputs": [],
      "source": [
        "# Connecting Google Drive to the CodeFile in Colab\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# setting the Path for the dataset\n",
        "train_path = '/content/drive/My Drive/chest_xray/train'\n",
        "test_path = '/content/drive/My Drive/chest_xray/test'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functons:\n",
        "This part contains all the functions that are used in this code file with there respective doc strings"
      ],
      "metadata": {
        "id": "R7OsURfQ2P01"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vhNr2DV0hwda"
      },
      "outputs": [],
      "source": [
        "\n",
        "def barPlotForDataset(path, name):\n",
        "  \"\"\"\n",
        "  Function to draw the bar Plot\n",
        "  \"\"\"\n",
        "\n",
        "  # List of subdirectories\n",
        "  classes = ['NORMAL', 'PNEUMONIA']\n",
        "\n",
        "  # Initialize lists to store the number of images per class\n",
        "  num_images_per_class = []\n",
        "\n",
        "  # Iterate through each class directory\n",
        "  for class_name in classes:\n",
        "      # Count the number of files in the class directory\n",
        "      class_path = os.path.join(path, class_name)\n",
        "      num_images = len(os.listdir(class_path))\n",
        "      num_images_per_class.append(num_images)\n",
        "\n",
        "  print(num_images_per_class)\n",
        "\n",
        "\n",
        "\n",
        "  plt.figure(figsize=(6, 5))\n",
        "  plt.bar(classes, num_images_per_class, color='skyblue')\n",
        "  plt.xlabel('Classes')\n",
        "  plt.ylabel('Number of Images')\n",
        "  plt.title('Number of Images in the ' + name +' Folder')\n",
        "\n",
        "  #Adding labels to the bars\n",
        "  for i in range(len(classes)):\n",
        "      plt.text(i, num_images_per_class[i], str(num_images_per_class[i]), ha='center', va='bottom')\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_line_plot():\n",
        "  \"\"\"\n",
        "  Function to plot the Loss and Accuracy\n",
        "\n",
        "  \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(10,4))\n",
        "    sns.lineplot(x = history.epoch, y = history.history['loss'])\n",
        "    sns.lineplot(x = history.epoch, y = history.history['val_loss'])\n",
        "    ax.set_title('Learning Curve (Loss)')\n",
        "    ax.set_ylabel('Loss')\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylim(0, 0.5)\n",
        "    ax.legend(['train', 'val'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10,4))\n",
        "    sns.lineplot(x = history.epoch, y = history.history['binary_accuracy'])\n",
        "    sns.lineplot(x = history.epoch, y = history.history['val_binary_accuracy'])\n",
        "    ax.set_title('Learning Curve (Accuracy)')\n",
        "    ax.set_ylabel('Accuracy')\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylim(0.80, 1.0)\n",
        "    ax.legend(['train', 'val'], loc='best')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "QmPG0IADAKKq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "performance_metrics = {}\n",
        "\n",
        "\n",
        "\n",
        "def eval_model_2(model, heatmap_color = 'Reds', model_name='undefiend'):\n",
        "  \"\"\"\n",
        "  Function to evaluate the model with the test data and\n",
        "  store the Accuracy, Recall, Precision and F1 Score in the performance metrics variable\n",
        "\n",
        "  Args: model: Model, heatmap_color: color of the heatmap produced, model_name: Name of the model\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  performance_metrics[model_name] = []\n",
        "  # Reset the test data generator\n",
        "  ds_test.reset()\n",
        "\n",
        "  # Make predictions on the test dataset\n",
        "  predictions = model.predict(ds_test, steps=len(ds_test), verbose=0)\n",
        "\n",
        "  # Convert predicted probabilities to binary predictions (0 or 1)\n",
        "  pred_labels = np.where(predictions > 0.5, 1, 0)\n",
        "\n",
        "  # Map class labels to numerical values for true labels\n",
        "  num_label = {'Normal': 0, 'Pneumonia': 1}\n",
        "  Y_test = df_test_balanced['class'].map(num_label).astype(int)\n",
        "\n",
        "  # Calculate precision of the model\n",
        "  precision = precision_score(Y_test, pred_labels)\n",
        "  performance_metrics[model_name].append(precision)\n",
        "\n",
        "  # # Calculate accuracy of the model\n",
        "  # accuracy = accuracy_score(Y_test, pred_labels)\n",
        "\n",
        "  # Calculate recall of the model\n",
        "  recall = recall_score(Y_test, pred_labels)\n",
        "  performance_metrics[model_name].append(recall)\n",
        "\n",
        "  # Calculate F1 score of the model\n",
        "  f1 = f1_score(Y_test, pred_labels)\n",
        "  performance_metrics[model_name].append(f1)\n",
        "\n",
        "  score_1 = model.evaluate(ds_val, steps = len(val_df)/BATCH_SIZE, verbose = 0)\n",
        "  score_2 = model.evaluate(ds_test, steps = len(df_test_balanced), verbose = 0)\n",
        "  performance_metrics[model_name].append(score_1[1])\n",
        "    # Print the calculated metrics\n",
        "  print('Val loss:', score_1[0])\n",
        "  print('Val accuracy:', score_1[1])\n",
        "  print('Test loss:', score_2[0])\n",
        "  print('Test accuracy:', score_2[1])\n",
        "  print(\"Recall:\", recall)\n",
        "  print(\"Precision:\", precision)\n",
        "  print(\"F1 Score:\", f1)\n",
        "\n",
        "  # Plot the confusion matrix\n",
        "  conf_matrix = confusion_matrix(Y_test, pred_labels)\n",
        "  sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap= heatmap_color,\n",
        "              xticklabels=['Normal', 'Pneumonia'],\n",
        "              yticklabels=['Normal', 'Pneumonia'])\n",
        "  plt.xlabel(\"Predicted Label\")\n",
        "  plt.ylabel(\"True Label\")\n",
        "  plt.title(\"Confusion Matrix\")\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "wbHGYMw7BCMA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for model training\n",
        "\n",
        "def train_model(model):\n",
        "\n",
        "  history = model.fit(ds_train,\n",
        "          batch_size = 32, epochs = 50,\n",
        "          validation_data=ds_val,\n",
        "          callbacks=[early_stopping, plateau],\n",
        "          steps_per_epoch=(len(train_df)/32),\n",
        "          validation_steps=(len(val_df)/32));\n",
        "  return history"
      ],
      "metadata": {
        "id": "ZdxyPNQQaEPl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions for all Model Architectures"
      ],
      "metadata": {
        "id": "qOFKdBZUYIXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funciton for defining Custom CNN Model Architecture\n",
        "\n",
        "def custom_CNN_model():\n",
        "    \"\"\"\n",
        "    Implementation of a custom CNN model for binary image classification.\n",
        "\n",
        "    Returns:\n",
        "        Keras Model instance representing the custom CNN model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the input tensor with specified shape\n",
        "    inputs = Input(shape=(224, 224, 3))\n",
        "\n",
        "    # Convolutional layer blocks\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    # Flatten the feature maps to feed into a dense layer\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # Dense layers with dropout\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # Output layer with sigmoid activation for binary classification\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=inputs, outputs=outputs, name='custom_cnn_model')\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "TrjRI0Ag-LkA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Visualization"
      ],
      "metadata": {
        "id": "rKHfsh0YXVPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "barPlotForDataset(train_path, \"train\")\n",
        "barPlotForDataset(test_path, \"test\")"
      ],
      "metadata": {
        "id": "nbNgEzfvXSs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing The dataset\n"
      ],
      "metadata": {
        "id": "flGKUUfZ67N6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_normal = glob.glob(train_path + \"/NORMAL/*.jpeg\")\n",
        "train_pneumonia = glob.glob(train_path + \"/PNEUMONIA/*.jpeg\")\n",
        "\n",
        "test_normal = glob.glob(test_path + \"/NORMAL/*.jpeg\")\n",
        "test_pneumonia = glob.glob(test_path + \"/PNEUMONIA/*.jpeg\")\n",
        "\n",
        "# Create DataFrame for training data\n",
        "df_train_normal = pd.DataFrame({'class': 'Normal', 'image': train_normal})\n",
        "df_train_pneumonia = pd.DataFrame({'class': 'Pneumonia', 'image': train_pneumonia})\n",
        "\n",
        "# Calculate the number of samples in each class\n",
        "num_pneumonia = len(df_train_pneumonia)\n",
        "num_normal = len(df_train_normal)\n",
        "\n",
        "print(num_pneumonia, num_normal)\n",
        "\n",
        "# Oversample the Normal class to match the number of Pneumonia samples\n",
        "df_train_normal_oversampled = df_train_normal.sample(n=num_pneumonia, replace=True, random_state=42)\n",
        "\n",
        "# Concatenate oversampled Normal class and original Pneumonia class\n",
        "df_train_balanced = pd.concat([df_train_normal_oversampled, df_train_pneumonia])\n",
        "\n",
        "# Shuffle the DataFrame rows\n",
        "df_train_balanced = df_train_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Optional: Shuffle the test data as well\n",
        "df_test_normal = pd.DataFrame({'class': 'Normal', 'image': test_normal})\n",
        "df_test_pneumonia = pd.DataFrame({'class': 'Pneumonia', 'image': test_pneumonia})\n",
        "df_test_balanced = pd.concat([df_test_normal, df_test_pneumonia])\n",
        "\n",
        "df_test_balanced = df_test_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "# Now df_train_balanced and df_test_balanced have balanced classes"
      ],
      "metadata": {
        "id": "RyfRAarB3JoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0ogsjx36DDY"
      },
      "outputs": [],
      "source": [
        "# Spliting the train dataset into train and validation\n",
        "train_df, val_df = train_test_split(df_train_balanced, test_size = 0.20, random_state = 42, stratify = df_train_balanced['class'])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "NTvc23b17uTW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "fIPs5UGuyKYU"
      },
      "outputs": [],
      "source": [
        "# Defining the preprocessing that needs to be applied\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255\n",
        "                                  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uY1XphpY4MYL"
      },
      "outputs": [],
      "source": [
        "#  setting up train and test dataset into batchs of 32 and in greyscale\n",
        "\n",
        "ds_train = train_datagen.flow_from_dataframe(train_df,\n",
        "                                             #directory=train_path, #dataframe contains the full paths\n",
        "                                             x_col = 'image',\n",
        "                                             y_col = 'class',\n",
        "                                             target_size = (224, 224),\n",
        "                                             class_mode = 'binary',\n",
        "                                             batch_size = BATCH_SIZE,\n",
        "                                             seed = 42)\n",
        "\n",
        "ds_val = val_datagen.flow_from_dataframe(val_df,\n",
        "                                            #directory=train_path,\n",
        "                                            x_col = 'image',\n",
        "                                            y_col = 'class',\n",
        "                                            target_size = (224, 224),\n",
        "                                            class_mode = 'binary',\n",
        "                                            batch_size = BATCH_SIZE,\n",
        "                                            seed = 42)\n",
        "\n",
        "ds_test = val_datagen.flow_from_dataframe(df_test_balanced,\n",
        "                                            #directory=test_path,\n",
        "                                            x_col = 'image',\n",
        "                                            y_col = 'class',\n",
        "                                            target_size = (224, 224),\n",
        "                                            class_mode = 'binary',\n",
        "                                            batch_size = 1,\n",
        "                                            shuffle = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Callbacks"
      ],
      "metadata": {
        "id": "6gn7HQvj78EU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hllyxuCU87Bw"
      },
      "outputs": [],
      "source": [
        "#Setting callbakcs\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    min_delta=1e-7,\n",
        "    restore_best_weights=True,\n",
        "\n",
        ")\n",
        "\n",
        "plateau = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor = 0.2,\n",
        "    patience = 2,\n",
        "    min_delt = 1e-7,\n",
        "    cooldown = 0,\n",
        "    verbose = 1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom CNN"
      ],
      "metadata": {
        "id": "KTewLtWI9-1d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asGzlhuY87IP"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "# model = get_model()\n",
        "model = custom_CNN_model()\n",
        "model.compile(loss='binary_crossentropy', optimizer = keras.optimizers.Adam(learning_rate=3e-5), metrics='binary_accuracy')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyjhCLpd-WMt"
      },
      "outputs": [],
      "source": [
        "\n",
        "history = train_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxCggvHw-WRF"
      },
      "outputs": [],
      "source": [
        "\n",
        "draw_line_plot()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model_2(model,'Greens','custom_CNN')"
      ],
      "metadata": {
        "id": "QJ3j6I57ZTc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Transfer Learning with Densenet model\n"
      ],
      "metadata": {
        "id": "iOorSetpbB9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def build_densenet_model(input_shape=(224, 224, 3), num_classes=1):\n",
        "    # Loading DenseNet121 pretrained on ImageNet without the top (fully connected) layers\n",
        "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    # Freezing the layers of the base model\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Adding custom top layers for binary classification\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    predictions = Dense(num_classes, activation='sigmoid')(x)\n",
        "\n",
        "    # Creating the final model\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "input_shape = (224, 224, 3)  # Input shape of the images\n",
        "num_classes = 1  # Binary classification (pneumonia detection)\n",
        "\n",
        "# Building the DenseNet model for transfer learning\n",
        "model = build_densenet_model(input_shape=input_shape, num_classes=num_classes)\n",
        "\n",
        "# Compiling the model with appropriate loss and metrics\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
        "\n",
        "# Model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "PXAuwYKpa-0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = train_model(model)"
      ],
      "metadata": {
        "id": "dMjkAfkCbJd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_line_plot()"
      ],
      "metadata": {
        "id": "EJsPpx3KbJih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model_2(model,'Reds','DenseNet')"
      ],
      "metadata": {
        "id": "UaIbNm4MbJmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer Learning with ResNet Model"
      ],
      "metadata": {
        "id": "i90iPBn-Zea_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEhhi9t3M8mM"
      },
      "outputs": [],
      "source": [
        "base_model = tf.keras.applications.ResNet152V2(\n",
        "    weights='imagenet',\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False)\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "def get_pretrained():\n",
        "\n",
        "    #Input shape = [width, height, color channels]\n",
        "    inputs = layers.Input(shape=(224, 224, 3))\n",
        "\n",
        "    x = base_model(inputs)\n",
        "\n",
        "    # Head\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "\n",
        "    #Final Layer (Output)\n",
        "    output = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = keras.Model(inputs=[inputs], outputs=output)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "model = get_pretrained()\n",
        "model.compile(loss='binary_crossentropy'\n",
        "              , optimizer = keras.optimizers.Adam(learning_rate=5e-5), metrics='binary_accuracy')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "9E_h1_aeWRAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model)"
      ],
      "metadata": {
        "id": "tgJoK1VKWREz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_line_plot()"
      ],
      "metadata": {
        "id": "d35qdzt2WwKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model_2(model,'Blues','ResNet')"
      ],
      "metadata": {
        "id": "cC3QIyiwW2rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet Fine-Tuned"
      ],
      "metadata": {
        "id": "zBeuzlVVmrUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "# Freezing all layers except for the\n",
        "for layer in base_model.layers[:-13]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "y8c51hn1orBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking which layers are tuneable (trainable)\n",
        "for layer_number, layer in enumerate(base_model.layers):\n",
        "    print(layer_number, layer.name, layer.trainable)"
      ],
      "metadata": {
        "id": "V1V8P91vorIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy'\n",
        "              , optimizer = keras.optimizers.Adam(learning_rate=2e-6), metrics='binary_accuracy')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "cVDhZUknorQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(ds_train,\n",
        "          batch_size = 32, epochs = 50,\n",
        "          validation_data=ds_val,\n",
        "          callbacks=[early_stopping, plateau],\n",
        "          steps_per_epoch=(len(train_df)/32),\n",
        "          validation_steps=(len(val_df)/32));"
      ],
      "metadata": {
        "id": "231DYoSnpDBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_line_plot()"
      ],
      "metadata": {
        "id": "hHCV_f-gDJaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model_2(model, 'Blues','ResNet Fine-Tuned')"
      ],
      "metadata": {
        "id": "RW09MeMVpHdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Performance Metrics"
      ],
      "metadata": {
        "id": "zKQ_n8Aym0HU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(performance_metrics)"
      ],
      "metadata": {
        "id": "HFn8dUO0mzIK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "oU4KFlDZ9fqI",
        "R7OsURfQ2P01",
        "qOFKdBZUYIXZ",
        "rKHfsh0YXVPf",
        "flGKUUfZ67N6",
        "NTvc23b17uTW",
        "6gn7HQvj78EU",
        "KTewLtWI9-1d",
        "iOorSetpbB9t",
        "i90iPBn-Zea_",
        "TDgNoiWtwpi-"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
